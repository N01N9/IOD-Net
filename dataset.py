import torch
import torch.nn.functional as F
import random
from torch.utils.data import IterableDataset, DataLoader
from datasets import load_dataset, Audio
from huggingface_hub import list_repo_files  # ì¶”ê°€ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬

class NCGMStreamingDataset(IterableDataset):
    def __init__(self, repo_id, split="train", sample_rate=16000, duration=20.0, mask_prob=0.5, skip_count=0):
        # ... (ìƒ¤ë“œ ë¡œì§ ê¸°ì¡´ ìœ ì§€) ...
        print(f"ğŸ” {repo_id}ì—ì„œ ìƒ¤ë“œ ëª©ë¡ì„ ì¡°íšŒ ì¤‘...")
        all_files = list_repo_files(repo_id, repo_type="dataset")
        tar_shards = sorted([f for f in all_files if f.endswith(".tar") and split in f])
        
        shards_to_skip = skip_count // 1000
        remaining_offset = skip_count % 1000
        selected_shards = tar_shards[shards_to_skip:]
        
        self.audio_ds = load_dataset(
            repo_id, data_files=selected_shards, split=split, streaming=True
        ).cast_column("wav", Audio(sampling_rate=sample_rate))
        
        meta_stream = load_dataset(repo_id, data_files="metadata.jsonl", split="train", streaming=True)
        self.meta = {item["file_name"].replace(".wav", ""): item["utterances"] for item in meta_stream}
        
        self.sample_rate = sample_rate
        self.max_samples = int(sample_rate * duration)
        self.num_frames = 2001
        self.max_speakers = 6
        
        # [ìˆ˜ì • 1] ë§ˆìŠ¤í‚¹ í™•ë¥ ì„ ê¸°ë³¸ 0.5(50%)ë¡œ ìƒí–¥í•˜ì—¬ ë¬´ìŒ í•™ìŠµ ê¸°íšŒ í™•ëŒ€
        self.mask_prob = mask_prob

    def apply_aggressive_masking(self, audio, target_mask):
        """
        [ìˆ˜ì • 2] ë” ê¸¸ê³  ë‹¤ì–‘í•œ ë¬´ìŒ êµ¬ê°„ì„ ìƒì„±í•˜ì—¬ VAD í¸í–¥ ì œê±°
        """
        if random.random() < self.mask_prob:
            # 1~2ì´ˆ(50~250í”„ë ˆì„)ê°€ ì•„ë‹Œ 1~8ì´ˆ(100~800í”„ë ˆì„)ê¹Œì§€ ëŒ€í­ ëŠ˜ë¦¼
            mask_len_frames = random.randint(100, 800) 
            start_frame = random.randint(0, self.num_frames - mask_len_frames - 1)
            end_frame = start_frame + mask_len_frames
            
            # ì ˆëŒ€ì ì¸ 0(Digital Zero) ëŒ€ì‹  ì•„ì£¼ ë¯¸ì„¸í•œ ë…¸ì´ì¦ˆë¥¼ ì„ì–´ í˜„ì‹¤ì ì¸ ë¬´ìŒ êµ¬í˜„
            # ì´ëŠ” ëª¨ë¸ì´ "ì™„ì „í•œ 0"ì´ ì•„ë‹Œ "ì‘ì€ ì†Œë¦¬"ë„ ë¬´ìŒìœ¼ë¡œ ë³´ê²Œ í•¨
            audio[start_frame * 160 : end_frame * 160] = torch.randn(mask_len_frames * 160) * 0.0001
            
            # í•´ë‹¹ êµ¬ê°„ì˜ ì •ë‹µ ë§ˆìŠ¤í¬ë¥¼ 0ìœ¼ë¡œ í™•ì‹¤í•˜ê²Œ ë°€ì–´ë²„ë¦¼ (VAD íƒ€ê²Ÿì´ 0ì´ ë¨)
            target_mask[start_frame:end_frame, :] = 0.0
            
        return audio, target_mask

    def __iter__(self):
        for item in self.audio_ds:
            # Try multiple key formats
            raw_filename = item.get("file_name", "")
            key_candidates = [
                item.get("__key__", ""),
                raw_filename,
                raw_filename.replace(".wav", ""),
                raw_filename.split("/")[-1].replace(".wav", "")
            ]
            
            # Find the first key that exists in metadata
            key = None
            for k in key_candidates:
                if k and k in self.meta:
                    key = k
                    break
            
            if key is None:
                # print(f"Skipping: {key_candidates} not found in metadata keys (sample: {list(self.meta.keys())[:5]})") 
                continue

            # [ìˆ˜ì • 3] 5%ì˜ í™•ë¥ ë¡œ 'ì™„ì „ ë¬´ìŒ' ìƒ˜í”Œì„ ìƒì„± (Hard Negative)
            # ëª¨ë¸ì´ ì•„ë¬´ ì†Œë¦¬ë„ ì—†ì„ ë•Œ VADê°€ 0ì´ ë‚˜ì™€ì•¼ í•¨ì„ ê°•ì œë¡œ í•™ìŠµ
            force_total_silence = random.random() < 0.05
            
            audio = torch.tensor(item["wav"]["array"], dtype=torch.float32)
            if audio.ndim > 1: audio = audio.mean(dim=-1)
            
            # íŒ¨ë”© ë° ì»¤íŒ…
            if audio.numel() > self.max_samples:
                audio = audio[:self.max_samples]
            else:
                audio = F.pad(audio, (0, self.max_samples - audio.numel()))
            
            target_mask = torch.zeros(self.num_frames, self.max_speakers)
            exist_target = torch.zeros(self.max_speakers)
            
            if not force_total_silence:
                utterances = self.meta[key]
                speakers = sorted(set(u["speaker"] for u in utterances))
                
                for i, spk in enumerate(speakers[:self.max_speakers]):
                    exist_target[i] = 1.0
                    for u in utterances:
                        if u["speaker"] == spk:
                            s, e = int(u["start"] * 100), int(u["end"] * 100)
                            target_mask[max(0, s):min(self.num_frames, e), i] = 1.0
                
                # ê³µê²©ì ì¸ ë§ˆìŠ¤í‚¹ ì ìš©
                audio, target_mask = self.apply_aggressive_masking(audio, target_mask)
            else:
                # ì™„ì „ ë¬´ìŒì¸ ê²½ìš° ì˜¤ë””ì˜¤ì™€ ë§ˆìŠ¤í¬ ëª¨ë‘ 0 (ë¯¸ì„¸ ë…¸ì´ì¦ˆ ì¶”ê°€)
                audio = torch.randn_like(audio) * 0.0001
                # target_maskì™€ exist_targetì€ ì´ë¯¸ 0ìœ¼ë¡œ ì´ˆê¸°í™”ë¨
            
            yield {
                "audio": audio, 
                "t": torch.linspace(0, 1, steps=self.num_frames).unsqueeze(-1), 
                "target_mask": target_mask, 
                "exist_target": exist_target
            }

# get_dataloader ë“± ë‚˜ë¨¸ì§€ ì¸í„°í˜ì´ìŠ¤ëŠ” ë™ì¼í•˜ê²Œ ìœ ì§€í•˜ë˜ mask_prob=0.5 ê¶Œì¥

def get_dataloader(repo_id, batch_size=8, mask_prob=0.5, skip_count=0, num_workers=0):
    """ê¸°ì¡´ í˜¸ì¶œ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€"""
    dataset = NCGMStreamingDataset(
        repo_id=repo_id, 
        mask_prob=mask_prob, 
        skip_count=skip_count
    )
    
    return DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True)